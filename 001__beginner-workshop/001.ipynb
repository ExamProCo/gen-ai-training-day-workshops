{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always check your python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS SDK for Python, -q flag is for quiet\n",
    "%pip install -q boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always check your boto3 version\n",
    "%pip show boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a prompt optimized for Titan.\n",
    "# https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf\n",
    "prompt_titan = \"\"\"\n",
    "User: \n",
    "Sulfuric acid reacts with sodium chloride, and gives {{chemical1}} and {{chemical2}}:\n",
    "Bot:\n",
    "\"\"\"\n",
    "\n",
    "# This is a prompt optimized for Claude \n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\n",
    "prompt_claude = \"\"\"\n",
    "Human: \n",
    "Sulfuric acid reacts with sodium chloride, and gives <chemical1>_____</chemical1> and <chemical2>_____</chemical2>:\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you can invoke the model you need to enable model access in Amazon Bedrock\n",
    "\n",
    "import json\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html\n",
    "resp = client.invoke_model(\n",
    "  modelId='amazon.titan-text-express-v1',\n",
    "  body=json.dumps({\n",
    "    \"inputText\": prompt\n",
    "  })\n",
    ")\n",
    "body = json.loads(resp.get(\"body\").read())\n",
    "print(body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how the body and output structure is different\n",
    "# Notice how XML is much better handled by Claude Haiku 3\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\n",
    "\n",
    "# In the Workshop Studio we don't have access to calude v2\n",
    "#resp = client.invoke_model(\n",
    "#    modelId='anthropic.claude-v2',\n",
    "#    contentType='application/json',\n",
    "#    accept='application/json',\n",
    "#    body=json.dumps({\n",
    "#        \"prompt\": prompt,\n",
    "#        \"max_tokens_to_sample\": 200,\n",
    "#        \"temperature\": 1.0\n",
    "#    })\n",
    "#)\n",
    "#body = json.loads(resp.get(\"body\").read())\n",
    "#print(body['completion'])\n",
    "\n",
    "\n",
    "resp = client.invoke_model(\n",
    "    modelId='anthropic.claude-3-haiku-20240307-v1:0',\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    body=json.dumps({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 1.0,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    })\n",
    ")\n",
    "body = json.loads(resp.get(\"body\").read())\n",
    "print(body['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a helper.py and a text file loader\n",
    "from helper import load_text_file\n",
    "prompt = load_text_file(\"prompts/zero-shot.txt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.invoke_model(\n",
    "    modelId='anthropic.claude-3-haiku-20240307-v1:0',\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    body=json.dumps({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 1.0,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    })\n",
    ")\n",
    "body = json.loads(resp.get(\"body\").read())\n",
    "print(body['content'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
