{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always check your python version, most AI/ML workloads are designed around a specific version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS SDK for Python, -q flag is for quiet\n",
    "# This is preinstalled on SageMaker but local development you need to install boto3\n",
    "%pip install -q boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always check your boto3 version\n",
    "# Sometimes boto3 will throw errors if its out of date so check the version.\n",
    "%pip show boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are four different Bedrock APIs\n",
    "# bedrock-runtime is for invoking GenAI models.\n",
    "import boto3\n",
    "client = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse prompts 1-to-1 with different LLMs but for best results you need to optimize them\n",
    "\n",
    "# This is a prompt optimized for Titan.\n",
    "# Make note of User, Bot, and the {{brackets}}\n",
    "# https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf\n",
    "prompt_titan = \"\"\"\n",
    "User: \n",
    "Sulfuric acid reacts with sodium chloride, and gives {{chemical1}} and {{chemical2}}:\n",
    "Bot:\n",
    "\"\"\"\n",
    "\n",
    "# This is a prompt optimized for Claude \n",
    "# Make note of Human, Assistant and the <xml>tags</xml>\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\n",
    "prompt_claude = \"\"\"\n",
    "Human: \n",
    "Sulfuric acid reacts with sodium chloride, and gives <chemical1>_____</chemical1> and <chemical2>_____</chemical2>:\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html\n",
    "\n",
    "# InvokeModel directly calls the underlying API.\n",
    "# InvokeModel does not standarized inputs anda outputs\n",
    "\n",
    "# Amazon Titan Text Express is a small model\n",
    "# We do not expect it to perform this task well.\n",
    "# It could use fine-tuning to better form this task.\n",
    "resp = client.invoke_model(\n",
    "  modelId='amazon.titan-text-express-v1',\n",
    "  body=json.dumps({\n",
    "    \"inputText\": prompt_titan\n",
    "  })\n",
    ")\n",
    "body = json.loads(resp.get(\"body\").read())\n",
    "print(body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how Claude 2 inputs and outputs are different from Amazon Titan Text\n",
    "# Notice how Claude 2 use text completion instead of Messages API\n",
    "\n",
    "#resp = client.invoke_model(\n",
    "#    modelId='anthropic.claude-v2',\n",
    "#    contentType='application/json',\n",
    "#    accept='application/json',\n",
    "#    body=json.dumps({\n",
    "#        \"prompt\": prompt,\n",
    "#        \"max_tokens_to_sample\": 200,\n",
    "#        \"temperature\": 1.0\n",
    "#    })\n",
    "#)\n",
    "#body = json.loads(resp.get(\"body\").read())\n",
    "#print(body['completion'])\n",
    "\n",
    "\n",
    "# Notice how Claude 3 uses the Messages API\n",
    "# Newer Chat Completion models *standardize on this messages API format\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html\n",
    "# https://docs.anthropic.com/en/api/messages\n",
    "resp = client.invoke_model(\n",
    "    modelId='anthropic.claude-3-haiku-20240307-v1:0',\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    body=json.dumps({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt_claude}]}],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 1.0,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    })\n",
    ")\n",
    "body = json.loads(resp.get(\"body\").read())\n",
    "print(body['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a helper.py and a text file loader\n",
    "# Manging your prompt templates externally is best practice\n",
    "# We wrote the helper function using Amazon Q Developer its very simple text file loader\n",
    "from helper import load_text_file\n",
    "prompt = load_text_file(\"prompts/zero-shot.txt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is same code as before, we are just testing the external prompt\n",
    "resp = client.invoke_model(\n",
    "    modelId='anthropic.claude-3-haiku-20240307-v1:0',\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    body=json.dumps({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 1.0,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    })\n",
    ")\n",
    "body = json.loads(resp.get(\"body\").read())\n",
    "print(body['content'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
